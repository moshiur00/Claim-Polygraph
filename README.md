# Claim-Polygraph

Claim-Polygraph is an automated pipeline for extracting, analyzing, and fact-checking claims from news articles, YouTube videos, and other sources using LLMs and external fact-checking APIs.

## Features

- **Text Extraction**: Extracts readable text from web articles and transcribes spoken content from YouTube videos.
- **Claim Identification**: Uses ClaimBuster API to find the most check-worthy sentences.
- **Claim Extraction**: Extracts concise, verifiable claims from text using LLM prompts.
- **Fact-Checking**:
  - LLM-based fact-checking with standardized scoring and reasoning.
  - Integrates with Google Fact Check Tools API for external fact-check reviews.
- **Web Interface**: Flask-based UI for submitting text or URLs and viewing results.
- **Rich Output**: Displays claim-worthiness scores, fact-check verdicts, confidence bands, sources, and reasoning.

## Usage

- Paste raw text, a news/article URL, or a YouTube video URL into the input box.
- The system will extract text, identify claims, and run fact-checking.
- Results include:
  - Top claim-worthy sentences ([ClaimBuster](https://idir.uta.edu/claimbuster/))
  - LLM-based fact-checks with verdicts, confidence, reasoning, and sources ([OpenAI GPT](https://platform.openai.com/docs/))
  - External fact-check reviews from [Google Fact Check Tools](https://toolbox.google.com/factcheck/explorer)

## Quick Start

### Prerequisites

- Python 3.10+
- [ffmpeg](https://ffmpeg.org/) (for YouTube transcription)
- API keys for:
  - OpenAI (LLM)
  - ClaimBuster
  - Google Fact Check Tools

### Installation

```sh
git clone https://github.com/yourusername/claim-polygraph.git
cd claim-polygraph
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```

## APIs Used

- [OpenAI GPT](https://platform.openai.com/docs/)
- [ClaimBuster](https://idir.uta.edu/claimbuster/api/)
- [Google Fact Check Tools](https://developers.google.com/fact-check/tools/api/reference/rest)

---

# Confidence & Reliability Standardization of LLM Fact Checking

To ensure consistent and transparent fact-checking, every claim and overall text assessment follows a standardized scoring rubric.

### Confidence & Reliability Bands (0â€“100)

| Score Range | Band Label          |
| ----------- | ------------------- |
| 95â€“100      | Established Fact    |
| 85â€“94       | Very Likely         |
| 70â€“84       | Likely              |
| 55â€“69       | Uncertain / Mixed   |
| 35â€“54       | Doubtful            |
| 15â€“34       | Unlikely            |
| 0â€“14        | False / Unsupported |

### Scoring Checklist

- **Source Quality (SQ):** Primary/official > peer-reviewed > major media > other > blogs/social
- **Independence & Count (IC):** More independent, corroborating sources â†’ higher score
- **Consensus (CS):** Strong agreement among fact-checkers/experts â†’ higher score
- **Recency/Relevance (RR):** Current & relevant evidence â†’ higher score
- **Specificity/Verifiability (SV):** Concrete, measurable, and fact-checkable claims â†’ higher score
- **Conflict (CP):** Credible contradictory evidence reduces score

---

## ðŸ“Š Scoring Technique & Formula

Each claimâ€™s confidence score is derived using a **deterministic weighted formula**.

### Weights

- SQ (Source Quality): **0.30**
- IC (Independence & Count): **0.20**
- CS (Consensus): **0.20**
- RR (Recency/Relevance): **0.15**
- SV (Specificity/Verifiability): **0.10**
- CP (Conflict Penalty): **âˆ’0.15**

### Sub-scores (0â€“100 scale)

- **SQ:** Official/peer-reviewed (90â€“100), major media (75â€“89), mixed/unknown (50â€“74), blogs/social (0â€“49)
- **IC:** 3+ sources (95â€“100), 2 sources (85â€“94), 1 source (60â€“79), none (0â€“40)
- **CS:** Clear alignment (90â€“100), minor dissent (70â€“89), mixed (40â€“69), major dissent (0â€“39)
- **RR:** â‰¤12 months (90â€“100), â‰¤24 months (75â€“89), stable but older (60â€“79), stale (0â€“59)
- **SV:** Precise (85â€“100), definition-dependent (60â€“84), vague (0â€“59)
- **CP:** None (0), minor (âˆ’5 to âˆ’8), substantial (âˆ’9 to âˆ’12), strong contradiction (âˆ’13 to âˆ’15)

### Formula

```
Score = 100 * (0.30*SQ + 0.20*IC + 0.20*CS + 0.15*RR + 0.10*SV) + CP
```

After computing, scores are **rounded to the nearest integer** and mapped to the confidence bands.

---

## Overall Reliability Assessment

In addition to per-claim verdicts, the system generates an **Overall Reliability Assessment** of the text:

- **Reliability Score (0â€“100):** Computed using the same weighted rubric and formula.
- **Reliability Band:** Mapped to the same bands as above.
- **Summary Paragraph:** A concise analysis noting:
  - Major strengths (e.g., strong source consensus, official data support)
  - Weaknesses (e.g., lack of sources, outdated evidence, mixed findings)
  - Uncertainty or conflicts across claims
  - Overall trustworthiness of the text

---

## License

MIT License. See [LICENSE](LICENSE).

## Acknowledgments

- [ClaimBuster](https://idir.uta.edu/claimbuster/)
- [Google Fact Check Tools](https://toolbox.google.com/factcheck/explorer)
- [OpenAI](https://openai.com/)

```

```
